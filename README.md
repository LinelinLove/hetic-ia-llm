# hetic-ia-llm

## Lancer le projet avec Docker

### Sans RAG

Cloner le projet : `git clone https://github.com/LinelinLove/hetic-ia-llm.git`

Aller dans le r√©pertoire du projet : `cd hetic-ia-llm`

PS : Sur Windows ouvrir Docker Desktop au pr√©alable
`docker-compose up -d --build`

Regarder les logs : `docker-compose logs -f` et attendre que le chargement soit termin√© jusqu'√† qu'il a ces messages suivants :

```
writing manifest
success
ü§ñ Assistant Ollama - Tapez 'exit' pour quitter
-----------------------------------
```

Le projet est pr√™t √† √™tre lanc√© :
`docker-compose exec python-ollama python app.py`

Vous pouvez √† pr√©sent donnere des prompts √† l'IA ! (L'assistant met du temps √† r√©pondre)

### Avec RAG avec Cloud
